### 整体：通过cnn提取特征，然后给模型加上multihead来将注意力放在需要的部分上。

### 预训练pretrian.py：用于训练backbone模型。

### trainfsl：首先

## 问题：代码哪里体现了 “set to set”的思想？

传统方法为 “instance-instance”，认为是不同实例间的相似关系查询，比如1个query 对阵5个support，传统认为是每个样本间独立地进行比较，忽略了类别内部样本之间的关联；

Feat的set-set认为使用原型级别的集合交互，类的原型通过自注意力相互影响，然后在正则化任务中为每个类的所有样本（support&query）形成一个集合，通过self-attention来学习类别内部表示。

这样我很快就搞透了它的核心观点，真不错，如果我再6点选择逃避可能就不是这样了。明天又要多久才能突破呢？
